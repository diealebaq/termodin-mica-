# Proyecto: Primera y Segunda Ley de la Termodin√°mica

Este repositorio contiene una explicaci√≥n completa, organizada y entendible de las dos leyes esenciales de la termodin√°mica, ampliando conceptos fundamentales, como los microestados, aportes de diversos pensadores, f√≥rmulas y la historia detr√°s de estos principios, fundamentales para entender muchos comportamientos de la materia.

## Contenido del proyecto

- Primera Ley de la Termodin√°mica.
- Segunda Ley de la Termodin√°mica.
- Ejemplos y aplicaciones.

# Primera Ley de la Termodin√°mica

La Primera Ley establece que:

 - La energ√≠a no se crea ni se destruye, solo se transforma. Esta verdad universal, conocida como primera ley de la termodin√°mica, puede resumirse en una sencilla afirmaci√≥n: "La energ√≠a se conserva". Cualquier energ√≠a perdida por el sistema deber√° ser ganada por el entorno y viceversa.


# Definici√≥n Hist√≥rica de Entrop√≠a

La entrop√≠a es una funci√≥n de estado cuya variaci√≥n se define cl√°sicamente mediante la relaci√≥n dS = Œ¥Qrev‚Äã‚Äã/T, que expresa c√≥mo cambia la entrop√≠a cuando un sistema intercambia calor de manera reversible a una temperatura dada. Seg√∫n la interpretaci√≥n presentada en el texto, esta magnitud puede entenderse como una medida del grado de dispersi√≥n o distribuci√≥n de la energ√≠a en el sistema: cuanto m√°s extensamente puede repartirse la energ√≠a entre los distintos estados posibles bajo condiciones macrosc√≥picas fijas, mayor es la entrop√≠a. As√≠, la formulaci√≥n cl√°sica describe cuantitativamente el cambio de entrop√≠a en t√©rminos de calor reversible, mientras que su significado f√≠sico se relaciona con la tendencia natural de la energ√≠a a difundirse dentro del sistema.

## Clausius definio la entrop√≠a como:

                                                                 dS = Œ¥Qrev‚Äã‚Äã/T

Clausius introdujo por primera vez la palabra entrop√≠a, para describir una magnitud de estado asociada al calor, donde:


-  DS= Cambio infinitesimal de entrop√≠a

- Œ¥Qrev= Calor intercambiado de forma irreversible

- T= Temperatura absoluta

Para Clausius, la entrop√≠a es la magnitud que permite cuantificar el cambio del calor cuando este se reparte en un sistema a una temperatura dada durante un proceso reversible. Ese reparto del calor implica una disminuci√≥n en su capacidad para producir trabajo, lo que constituye la esencia de la irreversibilidad.

## Ejemplos donde se aplica

1. Expansi√≥n libre de un gas

1 mol de gas ideal se encuentra en un recipiente con volumen inicial 
ùëâùëñ=2L y se expande libremente hasta ùëâùëì=6L a temperatura constante ùëá=300K
No hay intercambio de calor con el entorno (expansi√≥n libre = adiab√°tica e irreversible).


                                                                ŒîS=nRln(Vi/‚ÄãVf)‚Äã‚Äã


ŒîS‚âà8.314√ó1.0986‚âà9.13J/K

La energ√≠a cin√©tica de las mol√©culas se distribuye ahora en un volumen mayor ‚Üí mayor dispersi√≥n de energ√≠a.

La entrop√≠a aumenta ŒîùëÜ>0, reflejando irreversibilidad seg√∫n Clausius.

2. Transferencia de calor entre cuerpos a distinta temperatura

Un bloque caliente de metal (ùê∂‚Ñé=200J/K ,ùëá‚Ñé=400‚ÄâK) cede calor a un bloque fr√≠o de agua (ùê∂ùëê=100J/K, ùëáùëê=300K) hasta que alcanzan equilibrio t√©rmico.

Tf=366.67K

Cambio de entro√≠a en cada cuerpo:

                                                                ŒîS=Cln(Ti/‚ÄãTf)


Bloque caliente: ŒîSh=200ln(366.67/400)‚Äã=200ln 0.9167‚âà200√ó(‚àí0.087)‚âà‚àí17.4J/K‚Äã‚Äã

Bloque fr√≠o: ŒîSc‚Äã=100ln(366.67/‚Äã300)=100ln 1.222‚âà100√ó0.200‚âà20.0J/K

Entrop√≠a total= ŒîStotal‚Äã=ŒîSh‚Äã+ŒîSc‚Äã=‚àí17.4+20.0‚âà2.6J/K

La entrop√≠a total aumenta, cumpliendo la segunda ley de termodin√°mica

El calor se dispersa del bloque caliente al fr√≠o, disminuyendo la energ√≠a utilizable para trabajo.

Representa la dispersi√≥n de energ√≠a t√©rmica hacia estados menos concentrados y la irreversibilidad del proceso.
## Referencias

1. https://espanol.libretexts.org/Bookshelves/Quimica/Qu%C3%ADmica_General/Libro%3A_Chem1_%28Inferior%29/15%3A_Termodin%C3%A1mica_de_Equilibrios_Qu%C3%ADmicos/15.03%3A_La_Segunda_Ley_de_la_Termodin%C3%A1mica
2. https://www.britannica.com/science/entropy-physics

   # Boltzmann y la entrop√≠a
Fue el f√≠sico austriaco Ludwig Boltzmann quien dio con la explicaci√≥n microsc√≥pica de la entrop√≠a y su crecimiento.

Una vez que se acepta la hip√≥tesis at√≥mica (y esto es importante, pues no todos la aceptaban para cuando Boltzmann public√≥ sus trabajos) se puede formalizar la idea de que en su evoluci√≥n, los sistemas tienden al desorden.

De hecho, la relaci√≥n entrop√≠a-desorden no es tan clara. Por ejemplo, si agitamos una mezcla de agua y aceite, obtenemos un batiburrillo de burbujas de aceite dentro del agua que tildar√≠amos de desordenado. Y aun as√≠, el aceite y el agua se segregan ellos solitos en dos capas diferenciadas, que al ojo inocente le parecen m√°s ordenadas. Pero realmente aqu√≠ se ha respetado la segunda ley, y ha habido un aumento de entrop√≠a. De igual forma, si comenzamos con una nube de part√≠culas en el espacio que se atraen gravitacionalmente, podemos acabar formando estrellas, planetas, agujeros negros‚Ä¶ De nuevo, estos sistemas, aunque parezcan m√°s ordenados, tienen m√°s entrop√≠a que el sistema inicial.

Pero volvamos a Boltzmann y su explicaci√≥n de la entrop√≠a. Como pone en su l√°pida, Boltzmann defini√≥ la entrop√≠a como:

                                                        S = k \ ln W

donde k es una constante (la constante de Boltzmann, que por cierto la introdujo Max Planck) que ajusta las unidades, \ln es el logaritmo neperiano y W es el n√∫mero de maneras en las que podemos reorganizar microsc√≥picamente el sistema sin que nada cambie macrosc√≥picamente.

# Microestados
*¬øPor qu√© tiene sentido que esta sea la definici√≥n microsc√≥pica de la entrop√≠a?*

Pensemos en un gas. Supongamos que parte de un cierto volumen chiquit√≠n en la esquina de una habitaci√≥n.

Recuerda que en los gases lo que tenemos es un mont√≥n de mol√©culas con un movimiento aleatorio, que van rebotando unas con otras. Es l√≥gico que, en su evoluci√≥n, acaben por esparcirse por toda la habitaci√≥n, pues choque a choque, es mucho m√°s probable que las mol√©culas salgan despedidas en direcciones que hagan que se dispersen a que todas se conjuren para seguir chocando en un espacio reducido.

*¬øPor qu√© es m√°s probable? Pues aqu√≠ es cuando entra el concepto de microestado.*

Un microestado es una especificaci√≥n de las posiciones y velocidades de las part√≠culas que componen un sistema dado. Es decir, para un gas, deber√≠amos dar por cada mol√©cula su vector posici√≥n (3 datos) y su vector velocidad (3 datos), reuniendo una colecci√≥n de 6N datos si tenemos N mol√©culas.

# Referencias:
1. https://fisicatabu.com/el-origen-microscopico-de-la-entropia/
2. https://m.youtube.com/watch?v=SGl8lE6qp2g&pp=4gcNEgtjaGF0Z3B0LmNvbQ%3D%3D

## Definiciones alternativas y modernas de entrop√≠a
---
### Entrop√≠a como propiedad de la termodin√°mica 

***Se denomina entrop√≠a a la magnitud que indica la energ√≠a que no puede realizar un trabajo √∫til en un proceso termodin√°mico.***

La entrop√≠a se define como la medida de la dispersi√≥n de la energ√≠a en un sistema. Cuanto mayor es la entrop√≠a de un sistema, mayor es su grado de aleatoridad. Se puede pensar en la entrop√≠a como una medida de la cantidad de posibles configuraciones que puede tener un sistema, considerando todas las posibles combinaciones de part√≠culas y energ√≠a. Se denota con la letra S y se expresa en unidades de energ√≠a dividida por temperatura, generalmente en julios por kelvin (J/K).

La entrop√≠a f√≠sica, en su forma cl√°sica, es definida por la ecuaci√≥n propuesta por Rudolf Clausius:

                                                         dS = dQ / T

Esta es una magnitud termodin√°mica definida originalmente como criterio para predecir la evoluci√≥n de los sistemas termodin√°micos. En todo proceso irreversible, el desorden del sistema aumenta y por lo tanto, la entrop√≠a aumenta. Si el proceso es reversible, la variaci√≥n de entrop√≠a es nula.

La entrop√≠a de un sistema es una funci√≥n de estado de car√°cter extensivo. El valor de esta magnitud f√≠sica, en un sistema aislado, crece en el transcurso de un proceso que se da de forma natural. El concepto de entrop√≠a describe c√≥mo es de irreversible un sistema termodin√°mico.

En resumen, es un concepto fundamental en la termodin√°mica que se utiliza para medir la dispersi√≥n de la energ√≠a en un sistema y esta afecta la capacidad de un sistema para realizar trabajo √∫til.

**Aplicaciones:**

- Podemos encontrar la aplicaci√≥n de la entrop√≠a en las reacciones qu√≠micas. La variaci√≥n de entrop√≠a nos muestra la variaci√≥n del orden molecular ocurrido en una reacci√≥n qu√≠mica. Si el incremento de entrop√≠a es positivo, los productos presentan un mayor desorden molecular (mayor entrop√≠a) que los reactivos. En cambio, cuando el incremento es negativo, los productos son m√°s ordenados. Hay una relaci√≥n entre la entrop√≠a y la espontaneidad de una reacci√≥n qu√≠mica, que viene dada por la energ√≠a libre de Gibbs.

---
**Referencias:** 
1. https://solar-energia.net/termodinamica/propiedades-termodinamicas/entropia
2. https://conceptos.es/entropia-en-termodinamica
3. https://www.quimica.es/enciclopedia/Entrop%C3%ADa_%28termodin%C3%A1mica%29.html#Evidencias

---
### Entrop√≠a como calidad de informaci√≥n
*"La entrop√≠a en la teor√≠a mide la incertidumbre de los resultados y se aplica en la codificaci√≥n para optimizar la comprensi√≥n y transmisi√≥n de datos."*

La entrop√≠a en la teor√≠a de la informaci√≥n mide la incertidumbre o la cantidad de informaci√≥n contenida en fuentes de datos. Una mayor entrop√≠a indica una mayor incertidumbre y variabilidad de los datos. 

En codificaci√≥n, se busca minimizar la longitud promedio de los c√≥digos mediante comprensi√≥n, directamente influenciada por la entrop√≠a.

**Algunos esquemas de codificaci√≥n importantes incluyen:**

- **Codificaci√≥n Huffman:** Utiliza frecuencias de aparici√≥n de los s√≠mbolos para crear un √°rbol binario que asigna c√≥digos m√°s cortos a los s√≠mbolos m√°s comunes y c√≥digos m√°s largos a los menos comunes.

- **Codificaci√≥n Shannon-Fano:** Divide los s√≠mbolos en grupos basados en sus probabilidades y asigna c√≥digos de manera recursiva, asegurando que los s√≠mbolos m√°s probables tengan c√≥digos m√°s cortos.

- **Codificaci√≥n Aritm√©tica:** Representa un mensaje como un n√∫mero real en el intervalo [0,1), asignando subintervalos a cada s√≠mbolo basado en su probabilidad, permitiendo una compresi√≥n cercana a la entrop√≠a te√≥rica.
compresi√≥n cercana a la entrop√≠a te√≥rica.

**Aplicaciones Pr√°cticas**

El uso de la entrop√≠a y m√©todos de codificaci√≥n eficientes es cr√≠tico en diversas aplicaciones pr√°cticas, como:

- **Compresi√≥n de datos:** Algoritmos como ZIP y JPEG utilizan t√©cnicas basadas en la entrop√≠a para reducir el tama√±o de archivos y mejorar la eficiencia del almacenamiento y la transmisi√≥n de datos.

- **Transmisi√≥n de informaci√≥n:** En sistemas de comunicaci√≥n, minimizar la redundancia y optimizar la codificaci√≥n es esencial para maximizar la tasa de transmisi√≥n y reducir errores.

- **Criptograf√≠a:** La entrop√≠a se utiliza para evaluar la seguridad de sistemas criptogr√°ficos, garantizando que las claves y mensajes sean lo suficientemente impredecibles.

---
**Referencias:** 

1. https://www.thermal-engineering.org/es/la-entropia-en-la-teoria-de-la-informacion-y-la-codificacion/

---
### Entrop√≠a como entrelazamiento de la informaci√≥n 

La entrop√≠a de entrelazamiento es una medida de cu√°nta informaci√≥n se comparte entre diferentes partes de un sistema. Cuando dos sistemas est√°n entrelazados, conocer el estado de uno nos da informaci√≥n sobre el estado del otro. En nuestro caso, consideramos un sistema central (llam√©moslo sistema-A) y un sistema de ba√±o m√°s grande (sistema-B). Estos dos sistemas est√°n conectados, y sus tama√±os pueden cambiar mientras que el tama√±o total se mantiene fijo.

A medida que var√≠a el tama√±o de estos sistemas, sus propiedades de entrelazamiento tambi√©n cambian. Las leyes de conservaci√≥n de la energ√≠a gu√≠an estas variaciones, lo que significa que la energ√≠a se equilibra entre ambos sistemas.

Cuando exploramos la entrop√≠a del sistema de ba√±o en relaci√≥n con el sistema central, surgen dos conceptos importantes: "islas" e "icebergs".

- Islas se refieren a regiones espec√≠ficas dentro del ba√±o que contribuyen a la entrop√≠a total. Estas regiones est√°n generalmente separadas del sistema principal, pero juegan un papel crucial en c√≥mo se comparte la informaci√≥n.
- Icebergs son considerados como contribuciones m√°s peque√±as a la entrop√≠a que, aunque no sean tan significativas por s√≠ solas, juntas forman una parte importante de la entrop√≠a total.
  
Tanto las islas como los icebergs ayudan a crear una comprensi√≥n m√°s completa de c√≥mo opera el entrelazamiento dentro de estos sistemas.

La interacci√≥n entre el sistema-A y el sistema-B puede cambiar dependiendo de sus tama√±os individuales. Cuando el sistema-B es significativamente m√°s grande que el sistema-A, la relaci√≥n entre sus entrop√≠as se vuelve m√°s clara. En casos donde el sistema-B es peque√±o, las contribuciones de las islas y los icebergs pueden desconectarse, llevando a valores de entrop√≠a calculados de manera independiente.

Sin embargo, a medida que los sistemas crecen y var√≠an en tama√±o, su entrelazamiento tambi√©n se vuelve estrechamente vinculado. La entrop√≠a del ba√±o puede verse influenciada significativamente en funci√≥n de cu√°n grande es el sistema-A, reforzando la idea de conservaci√≥n de la entrop√≠a local.

Para calcular la entrop√≠a de entrelazamiento, primero se calcula la matriz densidad reducida para uno de los subsistemas, digamos A:

                                                            œÅA=TrB(|œàAB‚ü©‚ü®œàAB|)

Luego, se computa la entrop√≠a de von Neumann de œÅA:

                                                             SA=‚ÄìTr(œÅAlogœÅA)

Esta cantidad, SA, es la entrop√≠a de entrelazamiento del sistema conjunto AB. En sistemas bipartitos puramente entrelazados, la entrop√≠a de entrelazamiento es m√°xima, indicando una fuerte correlaci√≥n cu√°ntica.

**Aplicaciones**

- Un ejemplo cl√°sico de un estado entrelazado es el estado de Bell, que es una superposici√≥n de dos estados cu√°nticos base:

                                                           |œàAB‚ü©=12‚Äì‚àö(|00‚ü©+|11‚ü©)

  En este caso, si se efect√∫a una medida en uno de los subsistemas, el estado del otro subsistema queda instant√°neamente determinado, mostrando una correlaci√≥n perfecta entre A y B.

- Otro ejemplo es en la termodin√°mica, donde la entrop√≠a cl√°sica mide el desorden o la incertidumbre en un sistema. De manera similar, la entrop√≠a de entrelazamiento puede interpretarse como una medida de la incertidumbre o la correlaci√≥n intr√≠nseca entre los subsistemas en un estado cu√°ntico.
  
  Un aspecto fascinante de la entrop√≠a de entrelazamiento es su comportamiento en fases cr√≠ticas de la materia. En f√≠sica de la materia condensada, se ha observado que la entrop√≠a de entrelazamiento puede revelar informaci√≥n sobre transiciones de fase cu√°ntica y la estructura de correlaci√≥n en sistemas de muchos cuerpos.

  Adem√°s, en el contexto de la gravitaci√≥n cu√°ntica y la teor√≠a de cuerdas, la entrop√≠a de entrelazamiento juega un papel crucial en la comprensi√≥n de la din√°mica de agujeros negros y la holograf√≠a. Por ejemplo, el principio hologr√°fico sugiere que toda la informaci√≥n contenida en un volumen de espacio puede ser descrita por una teor√≠a que reside en su frontera. En estos estudios, la entrop√≠a de entrelazamiento es esencial para entender c√≥mo se almacena y se transfiere la informaci√≥n.

---
**Referencias:** 

1. https://modern-physics.org/entropia-de-entrelazamiento-vision-general-y-significado/ 
  
---

# Segunda Ley de la Termodin√°mica

La Segunda Ley introduce el concepto de **entrop√≠a** y establece la direcci√≥n natural de los procesos, en esta , diversos autores han hecho aportes a la intepretacion de esta ley, las cuales permitireon llegar hasta la intepretacion actual.

# Definiciones de Entrop√≠a seg√∫n diferentes autores

La entrop√≠a es uno de los conceptos m√°s importantes y complejos de la termodin√°mica. A lo largo de la historia, diferentes autores la han definido seg√∫n el enfoque te√≥rico utilizado: termodin√°mico cl√°sico, estad√≠stico, f√≠sico-qu√≠mico o ingenieril. 

---

## 1. Rudolf Clausius (1850‚Äì1865)
**Padre del concepto de entrop√≠a.**  
Clausius introdujo el t√©rmino entrop√≠a y la relacion√≥ con la energ√≠a t√©rmica no disponible para realizar trabajo.

**Definici√≥n:**
> "La entrop√≠a es una magnitud del estado que describe la parte de la energ√≠a que no puede transformarse en trabajo mec√°nico".

Adem√°s, estableci√≥ la famosa relaci√≥n:

                                                        ùëëùëÜ=ùõøùëÑrev/ùëá

Clausius tambi√©n formul√≥ la expresi√≥n:
> *"La entrop√≠a del universo tiende a un m√°ximo."*

Esta fue la primera articulaci√≥n clara de la irreversibilidad de los procesos naturales.

---

## 2. Ludwig Boltzmann (1877)
Boltzmann dio a la entrop√≠a una interpretaci√≥n estad√≠stica profunda.

**Definici√≥n:**
> "La entrop√≠a es una medida del n√∫mero de microestados accesibles por un sistema".

                                                         ùëÜ=ùëòln‚Å°Œ©

Donde:
- \( \Omega \) es el n√∫mero de microestados compatibles con un macroestado,
- \( k \) es la constante de Boltzmann.

**Aporte clave:**  
Introduce la idea de que la entrop√≠a est√° relacionada con el **desorden molecular**, dando una base microsc√≥pica a la termodin√°mica.

---

## 3. J. Willard Gibbs (1902)
Gibbs extendi√≥ y generaliz√≥ la definici√≥n estad√≠stica de la entrop√≠a.

**Definici√≥n:**
> "La entrop√≠a es una funci√≥n que depende de la probabilidad de los microestados y mide la distribuci√≥n de energ√≠a en un sistema".

                                                        ùëÜ=‚àíùëò‚àëùëùùëñlnùëùùëñ
													   
Es fundamental para describir sistemas con microestados no equiprobables.

---

## 4. Max Planck (1900‚Äì1917)
Planck utiliz√≥ la entrop√≠a como fundamento para su formulaci√≥n de la teor√≠a cu√°ntica.

**Definici√≥n:**
> "La entrop√≠a es una funci√≥n que determina la direcci√≥n natural de los procesos y cuya variaci√≥n describe la irreversibilidad".

Para √©l, la entrop√≠a era la clave para entender la naturaleza del equilibrio y la radiaci√≥n.

---

## 5. Peter Atkins (2014)
Atkins moderniz√≥ el concepto para facilitar su comprensi√≥n en qu√≠mica f√≠sica.

**Definici√≥n:**
> "La entrop√≠a es una medida de la dispersi√≥n de la energ√≠a y del modo en que se distribuye en un sistema".

**Aporte clave:**  
Sustituye el concepto tradicional de ‚Äúdesorden‚Äù por **dispersi√≥n de energ√≠a**, evitando interpretaciones ambiguas.

---

## 6. P. W. Bridgman (1961)
Bridgman, premio Nobel, enfatiz√≥ el car√°cter experimental y operacional.

**Definici√≥n:**
> "La entrop√≠a es una medida de la irreversibilidad de un proceso y del desgaste energ√©tico inevitable que limita el trabajo √∫til".

Describe la entrop√≠a en t√©rminos de la imposibilidad pr√°ctica de revertir un proceso real.

---

## 7. Herbert Callen (1985)
Callen ofreci√≥ una formulaci√≥n matem√°tica rigurosa de la termodin√°mica.

**Definici√≥n:**
> "La entrop√≠a es la funci√≥n que establece la estructura de equilibrio de la termodin√°mica y determina la direcci√≥n de la evoluci√≥n espont√°nea".

Para Callen, la entrop√≠a es la **funci√≥n fundamental del equilibrio**.

---

## 8. Smith, Van Ness y Abbott (Termodin√°mica Qu√≠mica, 2005)
Autores clave para ingenier√≠a qu√≠mica.

**Definici√≥n:**
> "La entrop√≠a es una propiedad que describe el grado de dispersi√≥n de la energ√≠a y el n√∫mero de configuraciones moleculares accesibles".

Integra el enfoque energ√©tico y estad√≠stico en una sola definici√≥n.

---

## 9. √áengel y Boles (Ingenier√≠a, 2015)
Muy usado en ingenier√≠a mec√°nica y qu√≠mica.

**Definici√≥n:**
> "La entrop√≠a es una medida cuantitativa del desorden molecular y del grado de irreversibilidad asociado a un proceso".

Destaca la conexi√≥n entre entrop√≠a, aleatoriedad molecular e irreversibilidad.

---

## 10. Ilya Prigogine (Sistemas alejados del equilibrio)
Premio Nobel por estudios sobre termodin√°mica del no equilibrio.

**Definici√≥n:**
> "La entrop√≠a describe la producci√≥n de irreversibilidad en sistemas alejados del equilibrio y su tendencia natural hacia nuevas estructuras o estados".

Fue pionero en entender c√≥mo sistemas complejos pueden generar orden mientras aumenta la entrop√≠a global.

---
# Entrop√≠a del Universo, del Sistema y del Entorno

La entrop√≠a es una propiedad termodin√°mica fundamental para entender la direcci√≥n natural de los procesos y la irreversibilidad. Para analizar un fen√≥meno se divide el universo en dos partes:

- **Sistema:** la porci√≥n del universo que se estudia.
- **Entorno (o alrededores):** todo lo que rodea al sistema.

La suma de ambos constituye el **universo termodin√°mico**.

---

# 1. Entrop√≠a del Universo

La entrop√≠a total del universo se define como la suma de la entrop√≠a del sistema y la del entorno:


                                             ŒîS universo = ŒîS sistema + ŒîS entorno

De acuerdo con la **segunda ley de la termodin√°mica**:

- **Procesos espont√°neos:**
   
                                                     ŒîS universo > 0

- **Procesos reversibles:**
  
                                                     ŒîS universo = 0

- **Procesos imposibles f√≠sicamente:**
  
                                                     ŒîS universo < 0


### Interpretaci√≥n:
La entrop√≠a del universo mide la **irreversibilidad global**.  
Toda fricci√≥n, resistencia, mezcla, disipaci√≥n de calor o turbulencia incrementa la entrop√≠a del universo.

Por eso afirmamos que:

> **La entrop√≠a del universo siempre aumenta para cualquier proceso real.**

---

# 2. Entrop√≠a del Sistema

El sistema es la parte que se analiza: un gas, una sustancia, una reacci√≥n qu√≠mica, un motor, etc.

La entrop√≠a del sistema var√≠a seg√∫n los cambios internos de energ√≠a y el estado termodin√°mico.

### Para procesos reversibles:

                                                      dS sistema = Œ¥Qrev/T

### Para cambios de estado a temperatura constante:

                                                      dS sistema = Qrev/T

### Propiedades importantes:

- El sistema **puede ganar o perder entrop√≠a**.
- La entrop√≠a del sistema **no determina la espontaneidad** por s√≠ sola.
- Depende del estado interno, del volumen, temperatura y microestados accesibles.

### Interpretaci√≥n:
La entrop√≠a del sistema mide:

- El **grado de dispersi√≥n** de la energ√≠a interna.  
- El **n√∫mero de configuraciones microsc√≥picas** posibles.  
- El **nivel de desorden molecular**.

---

# 3. Entrop√≠a del Entorno (o Alrededores)

En la mayor√≠a de an√°lisis, el entorno se modela como un **reservorio t√©rmico** grande cuya temperatura no cambia.

Si el sistema intercambia calor Q con el entorno:

### Si el sistema recibe calor:

                                                        S = -Q / T entorno

### Si el sistema pierde calor:

                                                        S = +Q / T entorno

### Interpretaci√≥n:
La entrop√≠a del entorno representa c√≥mo afecta el proceso al resto del universo.  
Es siempre opuesta al cambio de entrop√≠a del sistema porque el calor ganado por uno es perdido por el otro.

---

**Referencias:** 
1. https://www.rasc.es/blogacademia/?p=24240
2. https://onlinelibrary.wiley.com/doi/10.1155/2020/8769060
3. https://www.fisicalab.com/apartado/segundo-principio-termo
